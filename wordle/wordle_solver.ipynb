{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordle Solver\n",
    "## Curtis Peterson\n",
    "\n",
    "This notebook contains a solver for the [wordle](https://www.powerlanguage.co.uk/wordle/) puzzle. The solver uses a one-hot encoder to create $130$ (i.e. $5*26$) variables that correspond to each letter of the alphabet in each of the 5 letter-positions. Each word in the list of valid words is therefore represented by a $130$-dimensional vector. A score is associated with each of the $130$ letter-position variables by adding the vectors associated with all valid words, allowing each word to be scored. The solver eliminates words from the list based on feedback from the game, giving each word a new score based on only the remaining possible words.\n",
    "\n",
    "This is a work in progress and may be difficult to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>h</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>l</td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>g</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>r</td>\n",
       "      <td>t</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4\n",
       "0  a  a  h  e  d\n",
       "1  a  a  l  i  i\n",
       "2  a  a  r  g  h\n",
       "3  a  a  r  t  i\n",
       "4  a  b  a  c  a"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df = pd.read_csv('cleaned_word_list.csv')\n",
    "word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9330, 130)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "encoded_word_list = enc.fit_transform(word_df)\n",
    "encoded_word_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "positions = [1,2,3,4,5]\n",
    "\n",
    "encoding_index = []\n",
    "n1 = 0\n",
    "for pos in positions:\n",
    "    for lett in letters:\n",
    "        encoding_index.append((lett,pos,n1))\n",
    "        n1 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_scores = encoded_word_list.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6804.0, 6676.0, 6364.0, 6175.0, 6127.0, 6122.0, 6105.0, 6085.0, 6069.0, 6016.0]\n",
      "      0  1  2  3  4\n",
      "6847  s  a  r  e  e\n",
      "7507  s  o  r  e  e\n",
      "7492  s  o  o  e  y\n",
      "7230  s  i  r  e  e\n",
      "1020  b  o  r  e  e\n",
      "6827  s  a  m  e  y\n",
      "6846  s  a  r  e  d\n",
      "1688  c  o  o  e  e\n",
      "6369  r  a  r  e  e\n",
      "4370  l  a  r  e  e\n"
     ]
    }
   ],
   "source": [
    "scores_temp = letter_scores*encoded_word_list\n",
    "scores = scores_temp.sum(axis=1)\n",
    "word_index = np.arange(len(scores))\n",
    "scores_sorted, index_sorted = [i[0] for i in sorted(zip(scores,word_index), reverse=True)], [i[1] for i in sorted(zip(scores,word_index), reverse=True)]\n",
    "print(scores_sorted[:10])\n",
    "print(word_df.iloc[index_sorted[:10]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_df_elim(incorrect_lett, correct_lett, correct_pos_lett, incorrect_pos_lett, max_occurrence_count, correct_lett_threshold, word_df):\n",
    "    filter1 = (word_df.isin(incorrect_lett).sum(axis=1) == 0)\n",
    "    \n",
    "    if len(correct_lett) > 0:\n",
    "        filter2 = (word_df.isin(correct_lett).sum(axis=1) >= correct_lett_threshold)\n",
    "    else:\n",
    "        filter2 = filter1\n",
    "    \n",
    "    filter3_temp = []\n",
    "    if len(correct_lett_pos) > 0:\n",
    "        for lett in correct_pos_lett:\n",
    "            filter3_temp.append(word_df.iloc[:,lett[0]] == lett[1])\n",
    "        filter3 = (pd.DataFrame(filter3_temp).all(axis=0))\n",
    "    else:\n",
    "        filter3 = filter1\n",
    "\n",
    "    filter4_temp = []\n",
    "    if len(incorrect_lett_pos) > 0:\n",
    "        for lett in incorrect_pos_lett:\n",
    "            filter4_temp.append(word_df.iloc[:,lett[0]] != lett[1])\n",
    "        filter4 = (pd.DataFrame(filter4_temp).all(axis=0))\n",
    "    else:\n",
    "        filter4=filter1\n",
    "\n",
    "    filter5_temp = []\n",
    "    if len(max_occurrence_count) > 0:\n",
    "        for lett in max_occurrence_count:\n",
    "            count_temp = (word_df == lett[1]).sum(axis=1)\n",
    "            filter5_temp.append(count_temp <= lett[0])\n",
    "        filter5 = pd.DataFrame(filter5_temp).all(axis=0)\n",
    "    else:\n",
    "        filter5 = filter1\n",
    "\n",
    "    filter = filter1 & filter2 & filter3 & filter4 & filter5\n",
    "    return filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver\n",
    "The solver is in the cell below. The 6 variables on the top line are lists that should be populated with feedback from the game. The lists can be added to as the game continues. The lists below are populated as an example with feedback from the game shown in the following image:\n",
    "\n",
    "![Cat](wordle_example.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0  1  2  3  4\n",
      "3952  i  r  o  n  y\n",
      "2312  d  r  o  n  y\n",
      "1828  c  r  o  n  y\n",
      "3426  g  r  o  v  y\n",
      "3413  g  r  o  d  y\n",
      "6149  p  r  o  x  y\n",
      "[22.0, 22.0, 22.0, 21.0, 21.0, 20.0]\n"
     ]
    }
   ],
   "source": [
    "incorrect_lett = ['s','a','e','f'] #Individual lower-case letters as strings. These are the letters that are not in the word.\n",
    "correct_lett = ['r'] #Individual lower-case letters as strings. These are the letters that are in the word, but at an unknown position. This is the yellow R in the image above.\n",
    "incorrect_lett_pos = [(2,'r')] #Tuple representing incorrect positions of correct letters. This passes the information that R is not in the third position.\n",
    "correct_lett_pos = [(1,'r'),(2,'o'),(4,'y')] #Tuple consisting correct position-letter pairs. These are the green R, O, and Y in the image above.\n",
    "max_occurrence_count = [(1,'r')] #Tuple representing the max number of a particular letter. This is the grey second R in the image above.\n",
    "correct_lett_threshold = 1 #This eliminates words that don't contain a certain number of letters from the correct_lett variable. Does not include correct_lett_pos.\n",
    "\n",
    "filter = word_df_elim(incorrect_lett,correct_lett,correct_lett_pos,incorrect_lett_pos,max_occurrence_count,correct_lett_threshold,word_df)\n",
    "good_index = word_index[filter]\n",
    "\n",
    "new_letter_scores = encoded_word_list[filter].sum(axis=0)\n",
    "new_scores_temp = new_letter_scores*encoded_word_list[filter,:]\n",
    "new_scores = new_scores_temp.sum(axis=1)\n",
    "new_word_index = np.arange(len(new_scores))\n",
    "\n",
    "good_scores_sorted, good_index_sorted = [i[0] for i in sorted(zip(new_scores,new_word_index), reverse=True)], [i[1] for i in sorted(zip(new_scores,new_word_index), reverse=True)]\n",
    "print(word_df[filter].iloc[good_index_sorted].head(20))\n",
    "print(good_scores_sorted[:7])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct answer in this case was PROXY."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
